{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "X_train = (train.iloc[: , 1:].values).astype(np.float)\n",
    "Y_train = (train.iloc[: , 0].values).astype(np.float)\n",
    "X_test = (test.values).astype(np.float)\n",
    "\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split( X_train, Y_train , test_size= 0.1, random_state=42)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0] , 28 , 28 , 1)\n",
    "X_test = X_test.reshape(X_test.shape[0] , 28 , 28 , 1)\n",
    "X_valid = X_valid.reshape(X_valid.shape[0] , 28 , 28 , 1)\n",
    "Y_train = to_categorical(Y_train)\n",
    "Y_valid = to_categorical(Y_valid)\n",
    "\n",
    "X_train /= 255.0 \n",
    "X_valid /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "train_mean = np.average(X_train)\n",
    "valid_mean = np.average(X_valid)\n",
    "test_mean = np.average(X_test)\n",
    "\n",
    "train_variance = np.var(X_train)\n",
    "valid_variance = np.var(X_valid)\n",
    "test_variance = np.var(X_test)\n",
    "\n",
    "X_train -= train_mean\n",
    "X_valid -= valid_mean\n",
    "X_test -= test_mean\n",
    "\n",
    "X_train /= train_variance\n",
    "X_valid /= valid_variance\n",
    "X_test /= test_variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(input_shape):\n",
    "    \n",
    "    Input = keras.layers.Input(input_shape)\n",
    "    \n",
    "    #Layer #1\n",
    "\n",
    "    X = keras.layers.Conv2D(16, (3,3), strides=(1, 1)  , padding = 'same')(Input)\n",
    "    X = keras.layers.Conv2D(32, (3,3), strides=(1, 1)  , padding = 'same')(X)\n",
    "    X = keras.layers.Dropout(0.15)(X)\n",
    "    X = keras.layers.BatchNormalization(axis = 3)(X)\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "    X = keras.layers.AveragePooling2D((2, 2) , 1 )(X)\n",
    "\n",
    "    #Layer #2\n",
    "    \n",
    "    X = keras.layers.Conv2D(32, (3,3), strides=(2, 2) , padding = 'same')(X)\n",
    "    X = keras.layers.Dropout(0.15)(X)\n",
    "    X = keras.layers.BatchNormalization(axis = 3)(X)\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "    X = keras.layers.AveragePooling2D((2 , 2) , 1)(X)\n",
    "    \n",
    "    #Layer #3\n",
    "     \n",
    "    X = keras.layers.Conv2D(64, (5,5) , strides=(2,2) ,  padding = \"same\")(X)\n",
    "    X = keras.layers.Dropout(0.15)(X)\n",
    "    X = keras.layers.BatchNormalization(axis = 3)(X)\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "    X = keras.layers.AveragePooling2D((2, 2) , 1)(X)\n",
    "    \n",
    "    #Layer #4\n",
    "    \n",
    "    X = keras.layers.Conv2D(128, (5,5) , strides=(2,2) ,  padding = \"same\")(X)\n",
    "    X = keras.layers.Dropout(0.15)(X)\n",
    "    X = keras.layers.BatchNormalization(axis = 3)(X)\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "    X = keras.layers.AveragePooling2D((2, 2) , 1)(X)\n",
    "        \n",
    "    X = keras.layers.Flatten()(X)\n",
    "    X = keras.layers.Dense(256 , activation='relu')(X)\n",
    "    X = keras.layers.Dropout(0.25)(X)\n",
    "    X = keras.layers.Dense(10 , activation='softmax')(X)\n",
    "\n",
    "    return keras.models.Model(inputs = Input , outputs = X)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DRmodel = model((28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 32)        4640      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 27, 27, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 64)          51264     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_3 (Average (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 3, 128)         204928    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3, 3, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_4 (Average (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 405,162\n",
      "Trainable params: 404,650\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DRmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "class TrackLoss(Callback):\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.valid_losses = []\n",
    "        self.train_losses = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.valid_losses.append(logs.get('val_loss'))\n",
    "        self.train_losses.append(logs.get('loss'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37800\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False, \n",
    "        samplewise_center=False, \n",
    "        featurewise_std_normalization=False, \n",
    "        samplewise_std_normalization=False, \n",
    "        zca_whitening=False,  \n",
    "        rotation_range=12,  \n",
    "        zoom_range = 0.1, \n",
    "        width_shift_range=0.1,  \n",
    "        height_shift_range=0.1,  \n",
    "        horizontal_flip=False, \n",
    "        vertical_flip=False)  \n",
    "\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "print len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "590/590 [==============================] - 35s 59ms/step - loss: 0.0180 - acc: 0.9946 - val_loss: 0.0190 - val_acc: 0.9943\n",
      "Epoch 2/40\n",
      "590/590 [==============================] - 42s 71ms/step - loss: 0.0172 - acc: 0.9945 - val_loss: 0.0191 - val_acc: 0.9945\n",
      "Epoch 3/40\n",
      "590/590 [==============================] - 43s 74ms/step - loss: 0.0166 - acc: 0.9949 - val_loss: 0.0186 - val_acc: 0.9945\n",
      "Epoch 4/40\n",
      "590/590 [==============================] - 44s 75ms/step - loss: 0.0187 - acc: 0.9943 - val_loss: 0.0191 - val_acc: 0.9945\n",
      "Epoch 5/40\n",
      "590/590 [==============================] - 44s 75ms/step - loss: 0.0166 - acc: 0.9949 - val_loss: 0.0188 - val_acc: 0.9945\n",
      "Epoch 6/40\n",
      "590/590 [==============================] - 45s 77ms/step - loss: 0.0197 - acc: 0.9944 - val_loss: 0.0187 - val_acc: 0.9945\n",
      "Epoch 7/40\n",
      "590/590 [==============================] - 45s 77ms/step - loss: 0.0161 - acc: 0.9950 - val_loss: 0.0190 - val_acc: 0.9945\n",
      "Epoch 8/40\n",
      "590/590 [==============================] - 45s 77ms/step - loss: 0.0177 - acc: 0.9947 - val_loss: 0.0196 - val_acc: 0.9945\n",
      "Epoch 9/40\n",
      "590/590 [==============================] - 45s 77ms/step - loss: 0.0184 - acc: 0.9942 - val_loss: 0.0197 - val_acc: 0.9943\n",
      "Epoch 10/40\n",
      "590/590 [==============================] - 46s 78ms/step - loss: 0.0168 - acc: 0.9947 - val_loss: 0.0194 - val_acc: 0.9945\n",
      "Epoch 11/40\n",
      "590/590 [==============================] - 46s 78ms/step - loss: 0.0196 - acc: 0.9938 - val_loss: 0.0190 - val_acc: 0.9945\n",
      "Epoch 12/40\n",
      "590/590 [==============================] - 46s 78ms/step - loss: 0.0176 - acc: 0.9948 - val_loss: 0.0191 - val_acc: 0.9945\n",
      "Epoch 13/40\n",
      "590/590 [==============================] - 46s 77ms/step - loss: 0.0194 - acc: 0.9943 - val_loss: 0.0192 - val_acc: 0.9948\n",
      "Epoch 14/40\n",
      "590/590 [==============================] - 47s 79ms/step - loss: 0.0191 - acc: 0.9946 - val_loss: 0.0187 - val_acc: 0.9945\n",
      "Epoch 15/40\n",
      "590/590 [==============================] - 46s 79ms/step - loss: 0.0177 - acc: 0.9949 - val_loss: 0.0192 - val_acc: 0.9943\n",
      "Epoch 16/40\n",
      "590/590 [==============================] - 47s 79ms/step - loss: 0.0181 - acc: 0.9945 - val_loss: 0.0194 - val_acc: 0.9945\n",
      "Epoch 17/40\n",
      "590/590 [==============================] - 47s 79ms/step - loss: 0.0176 - acc: 0.9946 - val_loss: 0.0193 - val_acc: 0.9943\n",
      "Epoch 18/40\n",
      "590/590 [==============================] - 47s 79ms/step - loss: 0.0182 - acc: 0.9942 - val_loss: 0.0191 - val_acc: 0.9945\n",
      "Epoch 19/40\n",
      "590/590 [==============================] - 46s 78ms/step - loss: 0.0175 - acc: 0.9948 - val_loss: 0.0189 - val_acc: 0.9945\n",
      "Epoch 20/40\n",
      "590/590 [==============================] - 44s 75ms/step - loss: 0.0180 - acc: 0.9948 - val_loss: 0.0190 - val_acc: 0.9940\n",
      "Epoch 21/40\n",
      "590/590 [==============================] - 44s 74ms/step - loss: 0.0174 - acc: 0.9947 - val_loss: 0.0190 - val_acc: 0.9943\n",
      "Epoch 22/40\n",
      "590/590 [==============================] - 44s 74ms/step - loss: 0.0163 - acc: 0.9948 - val_loss: 0.0186 - val_acc: 0.9945\n",
      "Epoch 23/40\n",
      "590/590 [==============================] - 44s 74ms/step - loss: 0.0181 - acc: 0.9944 - val_loss: 0.0188 - val_acc: 0.9945\n",
      "Epoch 24/40\n",
      "590/590 [==============================] - 44s 74ms/step - loss: 0.0182 - acc: 0.9945 - val_loss: 0.0190 - val_acc: 0.9943\n",
      "Epoch 25/40\n",
      "590/590 [==============================] - 44s 74ms/step - loss: 0.0179 - acc: 0.9946 - val_loss: 0.0192 - val_acc: 0.9943\n",
      "Epoch 26/40\n",
      "590/590 [==============================] - 46s 78ms/step - loss: 0.0184 - acc: 0.9944 - val_loss: 0.0192 - val_acc: 0.9943\n",
      "Epoch 27/40\n",
      "590/590 [==============================] - 48s 81ms/step - loss: 0.0183 - acc: 0.9943 - val_loss: 0.0197 - val_acc: 0.9943\n",
      "Epoch 28/40\n",
      "590/590 [==============================] - 45s 77ms/step - loss: 0.0189 - acc: 0.9946 - val_loss: 0.0196 - val_acc: 0.9943\n",
      "Epoch 29/40\n",
      "590/590 [==============================] - 45s 76ms/step - loss: 0.0174 - acc: 0.9947 - val_loss: 0.0195 - val_acc: 0.9940\n",
      "Epoch 30/40\n",
      "590/590 [==============================] - 46s 77ms/step - loss: 0.0185 - acc: 0.9944 - val_loss: 0.0198 - val_acc: 0.9940\n",
      "Epoch 31/40\n",
      "590/590 [==============================] - 43s 74ms/step - loss: 0.0170 - acc: 0.9952 - val_loss: 0.0192 - val_acc: 0.9943\n",
      "Epoch 32/40\n",
      "590/590 [==============================] - 44s 74ms/step - loss: 0.0167 - acc: 0.9947 - val_loss: 0.0191 - val_acc: 0.9943\n",
      "Epoch 33/40\n",
      "590/590 [==============================] - 44s 75ms/step - loss: 0.0186 - acc: 0.9946 - val_loss: 0.0190 - val_acc: 0.9945\n",
      "Epoch 34/40\n",
      "590/590 [==============================] - 44s 74ms/step - loss: 0.0201 - acc: 0.9940 - val_loss: 0.0187 - val_acc: 0.9945\n",
      "Epoch 35/40\n",
      "590/590 [==============================] - 45s 76ms/step - loss: 0.0172 - acc: 0.9948 - val_loss: 0.0190 - val_acc: 0.9945\n",
      "Epoch 36/40\n",
      "590/590 [==============================] - 43s 73ms/step - loss: 0.0188 - acc: 0.9946 - val_loss: 0.0189 - val_acc: 0.9943\n",
      "Epoch 37/40\n",
      "590/590 [==============================] - 44s 74ms/step - loss: 0.0187 - acc: 0.9941 - val_loss: 0.0186 - val_acc: 0.9948\n",
      "Epoch 38/40\n",
      "590/590 [==============================] - 44s 74ms/step - loss: 0.0173 - acc: 0.9953 - val_loss: 0.0188 - val_acc: 0.9945\n",
      "Epoch 39/40\n",
      "590/590 [==============================] - 44s 74ms/step - loss: 0.0180 - acc: 0.9947 - val_loss: 0.0189 - val_acc: 0.9948\n",
      "Epoch 40/40\n",
      "590/590 [==============================] - 44s 74ms/step - loss: 0.0172 - acc: 0.9949 - val_loss: 0.0189 - val_acc: 0.9945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbd2c08fed0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DRmodel.fit_generator(datagen.flow(X_train,Y_train, batch_size=64),\n",
    "                              epochs = 40, validation_data = (X_valid,Y_valid),\n",
    "                              verbose = 1, steps_per_epoch=len(X_train) // 64\n",
    "                              , callbacks=[l,lrd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTaEgIiJpCgUREUlTKIiISNr/B7Pg3QmsOUSEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbd7d7974d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel(\n",
    "    'Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.plot(range(1,41) , l.train_losses , '-r' , range(1,41) , l.valid_losses , '-b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = DRmodel.predict(X_test)\n",
    "labels = predictions.argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs = pd.DataFrame()\n",
    "outputs['Label'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs.to_csv(\"Predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
